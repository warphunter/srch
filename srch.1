.TH SRCH 1
.SH NAME
\fBsrch \fP- fast, multi-threaded file search utility like \fBfind\fP(1), with extended functionality
.SH SYNOPSIS
.B srch
[\fB-t\fP \fIcount|*\fP] [[\fB-n\fP|\fB-i\fP \fI[!]re1|re2|\.\.\.\fP | \fB-N\fP \fI[!]name\fP] [\fB-a\fP]]
          [\fB-e\fP \fIdir\fP \.\.\. | \fB-E\fP \fIdir\fP \.\.\. | -Z]
          [\fB-f\fP] [\fB-d\fP] [\fB-l\fP] [\fB-b\fP] [\fB-c\fP] [\fB-p\fP] [\fB-k\fP]
          [\fB-m\fP \fImaxdepth\fP|\fImindepth\fP-[\fImaxdepth\fP]]
          [\fB-x\fP] [\fB-z\fP] [\fB-j\fP] [\fB-0\fP] [\fB-w\fP] [\fB-H\fP] [\fB-r\fP \fIcmd\fP] [\fB-v\fP \fIcount\fP]
          [\fB-u\fP \fIuser\fP \.\.\. | \fB-U\fP \fIuser\fP \.\.\.] [\fB-g\fP \fIgroup\fP \.\.\. | \fB-G\fP \fIgroup\fP \.\.\.]
          [\fB-o\fP \fIdays\fP | \fB-O\fP \fIminutes\fP | \fB-P\fP \fItstamp-file\fP]
          [\fB-y\fP \fIdays\fP | \fB-Y\fP \fIminutes\fP | \fB-W\fP \fItstamp-file\fP]
          [\fB-s\fP [+|-]\fIsize\fP[k|m|g|t] | +\fIsize\fP[k|m|g|t]:-\fIsize\fP[k|m|g|t]]
          [\fB-D\fP \fIcount\fP | \fB-F\fP \fIcount\fP | \fB-M\fP \fIcount\fP
           | \fB-A\fP \fIcount\fP | \fB-L\fP \fIcount\fP | \fB-B\fP \fIcount\fP | \fB-R\fP \fIcount\fP] [\fB-I\fP \fIcount\fP]
          [\fB-q\fP | \fB-Q\fP] [\fB-X\fP] [\fB-S\fP] [\fB-T\fP] [\fB-V\fP] [\fB-h\fP] [\fIarg1\fP [\fIarg2\fP] \.\.\.]

.SH DESCRIPTION
Srch is like a Swiss Army knife for exploring file tree structures quickly. Srch is written to be a fast, multi-threaded alternative to \fBfind\fP(1), with simplified syntax and extended functionality.  While \fBfind\fP(1) is single-threaded, \fBsrch\fP will by default use up to 8 CPU cores to search for files in parallel.  The basic idea is to handle each subdirectory as an independent unit, and feed a number of threads with these units.  Provided the underlying storage system is fast enough, this scheme will speed up file search considerably, and ultimately minimize the need for \fBlocate\fP(1).

.SH OPTIONS
.TP
.B
\fB-t\fP \fIcount|*\fP
Run up to \fIcount\fP or \fI*\fP threads in parallel.
.RS
.IP \(bu 3
\fICount\fP must be a non-negative integer between 1 and 512.
.IP \(bu 3
\fI*\fP means all available CPU cores.
.IP \(bu 3
Defaults to (virtual) CPU count on host, up to 8.
.IP \(bu 3
Note that \fIcount\fP threads will be created in addition to the main thread,
so the total number of threads utilized, will be \fIcount+1\fP or \fI*+1\fP. The main thread will be mostly idle.
.RE
.TP
.B
\fB-n\fP \fI[!]re1\fP|\fIre2\fP|\.\.\.
.RS
Search for file names matching regular expression \fIre1\fP OR \fIre2\fP etc.
.IP \(bu 3
Use '!' to negate, i.e. search for file names NOT matching regular expression \fIre1\fP OR \fIre2\fP etc.
.IP \(bu 3
Extended regular expressions (REG_EXTENDED) are supported.
.IP \(bu 3
For an exact match, '^filename$' can be specified ("^filename$" on Windows).
.IP \(bu 3
To search for files containing a dot, '\\.' or \\\\. can be specified ("\\." on Windows).
.IP \(bu 3
Also consider option \fB-N\fP \fI[!]name\fP which gives better performance, especially on large directory structures.
.IP \(bu 3
Only one \fB-n\fP option is supported, and it can't be combined with \fB-N\fP/\fB-i\fP.
.RE
.TP
.B
\fB-i\fP \fI[!]re1\fP|\fIre2\fP|\.\.\.
.RS
Same as \fB-n\fP, but perform case insensitive pattern matching.
.IP \(bu 3
This option can't be combined with \fB-N\fP/\fB-n\fP.
.RE
.TP
.B
\fB-N\fP \fI[!]name\fP
.RS
Search for file names matching shell pattern *\fIname\fP* (case is ignored).
.IP \(bu 3
Use '!' to negate, i.e. search for file names NOT matching shell pattern *\fIname\fP*.
.IP \(bu 3
This is usually much faster than \fB-n\fP/\fB-i\fP when searching through millions of files.
.IP \(bu 3
This option is implemented to be simple and portable, and supports pure ASCII characters only.
.IP \(bu 3
Option \fB-N\fP is default if \fB-n\fP/\fB-i\fP is not given.
.IP \(bu 3
This option can't be combined with \fB-n\fP/\fB-i\fP.
.IP \(bu 3
Only one \fB-N\fP option is supported.
.RE
.TP
.B
\fB-a\fP
Together with option -n/-i/-N, match \fIre\fP or \fIname\fP against all of the directory elements 
in the tree structure being traversed,
treating '/' as an ordinary character, like GNU \fBlocate\fP(1).
.RE
.TP
.B
\fB-e\fP \fIdir\fP
Exclude directories matching \fIdir\fP from traversal.
.RS
.IP \(bu 3
Extended regular expressions are supported.
.IP \(bu 3
Any number of \fB-e\fP options are supported, up to command line limit.
.IP \(bu 3
This options can't be combined with \fB-E\fP.
.RE
.TP
.B
\fB-E\fP \fIdir\fP
Exclude directory \fIdir\fP from traversal.
.RS
.IP \(bu 3
For simplicity, only exact matches are excluded with this option.
.IP \(bu 3
Any number of \fB-E\fP options are supported, up to command line limit.
.IP \(bu 3
This options can't be combined with \fB-e\fP.
.IP \(bu 3
Hint: Excluding .snapshot is usually desired on (the root of) NFS mounted shares from NAS where visible snapshots are enabled.
.RE
.TP
.B
\fB-Z\fP
Equivalent to -E.snapshot.
.RS
.IP \(bu 3
Just to save some typing since it is commonly needed on a NAS NFS share.
.IP \(bu 3
Not implemented for Windows.
.RE
.TP
.B
\fB-f\fP
Print only ordinary files to stdout.
.TP
.B
\fB-d\fP
Print only directories to stdout.
.TP
.B
\fB-l\fP
Print only symlinks to stdout.
.TP
.B
\fB-b\fP
Print only block special files to stdout.
.TP
.B
\fB-c\fP
Print only character special files to stdout.
.TP
.B
\fB-p\fP
Print only named pipes/fifos to stdout.
.TP
.B
\fB-k\fP
Print only sockets to stdout.
.TP
.B
\fB-m\fP \fImaxdepth\fP|\fImindepth\fP-[\fImaxdepth\fP]]
.RS
\fB-m\fP \fImaxdepth\fP : Descend at most \fImaxdepth\fP levels below the start point(s).
.PP
\fB-m\fP \fImindepth\fP- : Descend at least \fImindepth\fP levels below the start point(s).
.PP
\fB-m\fP \fImindepth\fP-\fImaxdepth\fP : Descend between \fImindepth\fP and \fImaxdepth\fP levels below the start point(s).
.IP \(bu 3
This is similar to the \fB-maxdepth\fP and \fB-mindepth\fP options to GNU \fBfind\fP(1).
.RE
.TP
.B
\fB-x\fP
Only traverse the file system(s) containing the directory/directories specified.
.RS
.IP \(bu 3
This equals the \fB-xdev\fP option to \fBfind\fP(1).
.RE
.TP
.B
\fB-z\fP
Print out empty directories only.
.RS
.IP \(bu 3
This equals options "\fB-type\fP d \fB-empty\fP" to GNU \fBfind\fP(1).
.IP \(bu 3
This also equals 'srch -ds0', but is much faster because of fewer \fBlstat\fP(2) calls.
.IP \(bu 3
Apart from the exclude and age options, -z can only be combined with a few others, like -m/-x/-j/-0/-r.
.RE
.TP
.B
\fB-j\fP
Prepend filenames with modtime details.
.RS
.IP \(bu 3
Note that an extra \fBlstat\fP(2) call will be needed on non-directories.
.RE
.TP
.B
\fB-0\fP
Print file names followed by a null character instead of the default newline.
.RS
.IP \(bu 3
This equals the \fB-print0\fP option to GNU \fBfind\fP(1).
.IP \(bu 3
Whatever characters in the file names, we can search the tree starting at
the current directory by running something like this to delete the matched files (using GNU \fBxargs\fP(1))
.RE
.TP
.B
.RS
`\fBsrch\fP \fB-0\fP pattern | \fBxargs\fP \fB-0P\fP \fBrm\fP \fB-f\fP'
.RE
.TP
.B
\fB-w\fP
Print out the total number of files/directories in the selected tree structure(s).
.RS
.IP \(bu 3
Equivalent to running `\fBsrch\fP \fIargs\fP | wc \fB-l\fP` as long as there is no file name containing a newline.
.IP \(bu 3
This option may not be combined with \fB-z\fP (for implementation simplicity/execution speed).
.RE
.TP
.B
\fB-H\fP
Print out the sum of the file sizes, in powers of 1024, of all the files encountered.
.RS
.IP \(bu 3
Output is on a human-readable format, like `du -hs'.
.RE
.TP
.B
\fB-r\fP \fIcmd\fP
For each matched file/directory, execute the shell command \fIcmd\fP.
.RS
.IP \(bu 3
If \fIcmd\fP contains a space, it must be escaped by a '\\', or \fIcmd\fP must be enclosed by single or double quotes.
.IP \(bu 3
A character pair `{}' within \fIcmd\fP, is replaced by the current file path.
.IP \(bu 3
Note that just up to 2 occurences of the `{}' pair are replaced by the file path.
.IP \(bu 3
If more than 2 are needed, a variable f=`{}' can be introduced for one of the two pairs.
.IP \(bu 3
If no `{}' pair is found in \fIcmd\fP, the file path is appended at the end of \fIcmd\fP, enclosed by single quotes.
.IP \(bu 3
Using quotes around a brace pair is recommended, so that file names containing spaces are correctly handled.
.IP \(bu 3
If file path is not needed at the end of \fIcmd\fP, adding ' #' or ';:' to \fIcmd\fP, makes it invisible.
.IP \(bu 3
This option may be CPU intensive as it creates a new process for each file/directory matched, by default using 8 threads in parallel, or less if there are fewer cores.
.RE
.TP
.B
\fB-v\fP \fIcount\fP
Print out a progress line after every \fIcount\fP files have been processed.
.TP
.B
\fB-u\fP \fIuser\fP
Search for files owned by specific user name or uid.
.RS
.IP \(bu 3
Any number of -u options are supported, up to command line limit.
.RE
.TP
.B
\fB-U\fP \fIuser\fP
Search for files NOT owned by specific user name or uid.
.RS
.IP \(bu 3
Any number of -U options are supported, up to command line limit.
.RE
.TP
.B
\fB-g\fP \fIgroup\fP
Search for files owned by specific group name or gid.
.RS
.IP \(bu 3
Any number of -g options are supported, up to command line limit.
.RE
.TP
.B
\fB-G\fP \fIgroup\fP
Search for files NOT owned by specific group name or gid.
.RS
.IP \(bu 3
Any number of -G options are supported, up to command line limit.
.RE
.TP
.B
\fB-o\fP \fIdays\fP
Only print out files older than \fIdays\fP, i.e. modified more than \fIdays\fP ago.
.TP
.B
\fB-O\fP \fIminutes\fP
Only print out files older than \fIminutes\fP, i.e. modified more than \fIminutes\fP ago.
.TP
.B
\fB-P\fP \fItstamp-file\fP
Only print out files older than \fItstamp-file\fP, i.e. modified before \fItstamp-file\fP.
.TP
.B
\fB-y\fP \fIdays\fP
Only print out files younger than \fIdays\fP, i.e. modified less than \fIdays\fP ago.
.TP
.B
\fB-Y\fP \fIminutes\fP
Only print out files younger than \fIminutes\fP, i.e. modified less than \fIminutes\fP ago.
.TP
.B
\fB-W\fP \fItstamp-file\fP
Only print out files younger than \fItstamp-file\fP, i.e. modified after \fItstamp-file\fP.
.TP
.B
\fB-s\fP [+|-]\fIsize\fP[k|m|g|t] | +\fIsize\fP[k|m|g|t]:-\fIsize\fP[k|m|g|t]
Only print out files with size equal to, bigger than (+) or smaller than (-) \fIsize\fP bytes,
kibibytes (k), mebibytes (m), gibibytes (g) or tebibytes (t).
.RS
.IP \(bu 3
No spaces between [+|-] and \fIsize\fP and [k|m|g|t] are allowed.
.IP \(bu 3
Modifiers +/- include the \fIsize\fP given, e.g. -s+0 includes files of zero size, i.e. all files.
.IP \(bu 3
option -s+1 lists all non-zero files.
.IP \(bu 3
An interval can be specified using +\fIsize\fP[k|m|g|t]:-\fIsize\fP[k|m|g|t].
.IP \(bu 3
Only one -s option is currently supported.
.RE
.TP
.B
\fB-D\fP \fIcount\fP
Print out the path to the \fIcount\fP directories containing the highest number of files together with this number.
.RS
.IP \(bu 3
Note that if the highest number of files is found in several directories, and \fIcount\fP is 1, the
printed path is randomly chosen between these directories.
The same goes for any \fIcount\fP.
.RE
.RE
.TP
.B
\fB-F\fP \fIcount\fP
Print out the path to the \fIcount\fP biggest files together with the file size in bytes.
.RS
.IP \(bu 3
May be combined with options -o/-O/-y/-Y. Particularly, \fB-o\fP \fIdays\fP may be useful to find the biggest files older than a chosen number of days.
.IP \(bu 3
May also be combined with options -u/-U/-g/-G. Particularly, \fB-U root\fP may be useful to exclude files owned by root.
.IP \(bu 3
Note that if the biggest file size (default including directory sizes) is found several times, and \fIcount\fP is 1,
the printed path is randomly chosen between the equally sized files.
The same goes for any \fIcount\fP.
.RE
.RE
.TP
.B
\fB-M\fP \fIcount\fP
Print out the path to the \fIcount\fP most recently modified files/directories together with the time stamp.
.RS
.IP \(bu 3
Note that if the same time stamp is found on several files, and \fIcount\fP is 1, the
printed path is randomly chosen between these.
The same goes for any \fIcount\fP and identical time stamps.
.RE
.RE
.TP
.B
\fB-A\fP \fIcount\fP
Print out the path to the \fIcount\fP most recently accessed files/directories together with the time stamp.
.RS
.IP \(bu 3
Same comment as for \fB-M\fP \fIcount\fP.
.RE
.TP
.B
\fB-L\fP \fIcount\fP
Print out the path to the \fIcount\fP least recently modified files/directories together with the time stamp.
.RS
.IP \(bu 3
Same comment as for \fB-M\fP \fIcount\fP.
.RE
.TP
.B
\fB-B\fP \fIcount\fP
Print out the path to the \fIcount\fP least recently accessed files/directories together with the time stamp.
.RS
.IP \(bu 3
Same comment as for \fB-M\fP \fIcount\fP.
.RE
.TP
.B
\fB-R\fP \fIcount\fP
Print out the path to the \fIcount\fP dirctories furthest from the root(s) together with the depth.
.RS
.IP \(bu 3
Note that if there are several directories at an equal depth, and \fIcount\fP is 1, the
printed path is randomly chosen between these.
The same goes for any \fIcount\fP.
.RE
.RE
.TP
.B
\fB-I\fP \fIcount\fP
Use \fIcount\fP as number of subdirectories in a directory, that should
be processed in-line instead of processing them in separate threads.
.RS
.IP \(bu 3
Default is to process up to two subdirectories in a directory in-line.
.IP \(bu 3
If there are no more than \fIcount\fP subdirectories, all will be processed in-line.
.IP \(bu 3
If there are more than \fIcount\fP subdirectories, say \fIn\fP in total, the first \fIn\fP - \fIcount\fP will be enqueued to avoid thread starvation.
.IP \(bu 3
This is a performance option to possibly squeeze out even faster run-times.
.IP \(bu 3
Use 0 for processing every subdirectory in a separate thread, and no in-line processing.
.IP \(bu 3
A \fIcount\fP less than zero can be used to process every directory in-line in \fB-t\fP \fIthreads\fP, or default if \fB-t\fP is not specified.
.RE
.TP
.B
\fB-q\fP
Organize the queue of directories as a FIFO which may be faster in some cases (default is LIFO).
.RS
.IP \(bu 3
The speed difference between a LIFO and a FIFO queue is usually small.
.IP \(bu 3
Note that this option will use more memory.
.RE
.TP
.B
\fB-Q\fP
Organize the queue of directories as a binary search tree sorted on inode number.
.RS
.IP \(bu 3
Using this option with a file system on a single (or mirrored) spinning disk is recommended, at least on Linux.
.IP \(bu 3
Using it on a lun from a storage array or on SSD or FLASH disk is probably pointless.
.RE
.TP
.B
\fB-X\fP
May be used to speed up \fBsrch\fP'ing eXtremely big directories containing millions of files.
.RS
.IP \(bu 3
This option is probably just useful when the big directories being traversed are cached in memory.
.IP \(bu 3
With this option, default maximum number of dirents read in one go is 100000.
.IP \(bu 3
Environment variable DIRENTS may be set to override the default.
.IP \(bu 3
This option is only supported on Linux and *BSD flavors.
.RE
.TP
.B
\fB-S\fP
Print some stats to stderr when finished.
.TP
.B
\fB-T\fP
Print the elapsed real time between invocation and termination of the program on stderr, like \fBtime\fP(1).
.TP
.B
\fB-V\fP
Print out version and exit.
.TP
.B
\fB-h\fP
Print this help text.
.SH USAGE
.IP \(bu 3
If no argument is specified, current directory (.) will be traversed, and
all file and directory names found, will be printed in no particular order.
.IP \(bu 3
If one argument (\fIarg1\fP) is specified, and this is a directory or a symlink to a directory, it will be traversed, and
all file and directory names found, will be printed in no particular order.
.IP \(bu 3
If one argument (\fIarg1\fP) is specified, and this is not a directory nor a symlink to a directory, option \fB-N\fP is assumed, and
file names matching shell pattern "*\fIarg1\fP*" (ignoring case) are searched for in current directory (including subdirs).
.IP \(bu 3
If more than one argument (\fIarg1\fP \fIarg2\fP \.\.\.) is specified, and the first is not a directory, option \fB-N\fP is assumed,
and file names matching shell pattern "*\fIarg1\fP*" (ignoring case) are searched for in remaining arguments "\fIarg2\fP", \.\.\..
.IP \(bu 3
Ambiguity warning: If something like `\fBsrch\fP pat pat' is executed, and "pat" is a directory,
all the files in the "pat" tree structure will silently be listed twice.
Use option \fB-n\fP, \fB-N\fP or \fB-i\fP if
the intention is to search for files/dirs matching "pat" in directory "pat".
.RE
.IP \(bu 3
Options [\fB-F\fP \fIcount\fP | \fB-M\fP \fIcount\fP | \fB-A\fP \fIcount\fP | \fB-L\fP \fIcount\fP | \fB-B\fP \fIcount\fP] could slow down execution considerably
because they require an \fBlstat\fP(2) call for every file/directory in the specified directory \fBtree\fP(s).
.IP \(bu 3
Options [\fB-f\fP] [\fB-d\fP] [\fB-l\fP] [\fB-b\fP] [\fB-c\fP] [\fB-p\fP] [\fB-s\fP] may be combined in any order.
Note that using any of these might slow down the program considerably,
at least on AIX/HP-UX/Solaris because \fBlstat\fP(2) has to be called for every file.
These options may also be combined with one of [\fB-D\fP \fIcount\fP | \fB-F\fP \fIcount\fP | \fB-M\fP \fIcount\fP | \fB-A\fP \fIcount\fP | \fB-L\fP \fIcount\fP | \fB-B\fP \fIcount\fP]
to list out only files, directories etc.
.IP \(bu 3
The program has been tested on these file systems:
.RS
.IP \(bu 3
Linux: ext2, ext3, ext4, xfs, jfs, btrfs, nilfs2, f2fs, zfs, tmpfs
.IP
reiserfs, hfs plus, minix, bfs, ntfs (fuseblk), vxfs, gpfs
.IP \(bu 3
FreeBSD: ufs, zfs, devfs, ms-dos/fat
.IP \(bu 3
OpenBSD: ffs
.IP \(bu 3
NetApp (systemshell@FreeBSD): clusfs
.IP \(bu 3
MacOS: apfs
.IP \(bu 3
AIX: jfs, jfs2, ahafs
.IP \(bu 3
HP-UX: vxfs, hfs
.IP \(bu 3
Solaris: zfs, ufs, udfs
.IP \(bu 3
Windows: ntfs (MinGW, Cygwin)
.IP \(bu 3
All: nfs
.RE
.SH EXAMPLES
.IP \(bu 3
\fBExample 1\fP:
Searching in the GNU findutils sources
.RS
.PP
~/src/findutils-4.7.0# \fBls -F\fP
.br
ABOUT-NLS   ChangeLog    config.status*  doc/           GNUmakefile  locate/   Makefile.am  README          tests/             xargs/
.br
aclocal.m4  config.h     configure*      find/          init.cfg     m4/       Makefile.in  README-hacking  THANKS
.br
AUTHORS     config.h.in  configure.ac    gl/            INSTALL      maint.mk  NEWS         stamp-h1        TODO
.br
build-aux/  config.log   COPYING         gnulib-tests/  lib/         Makefile  po/          stamp-h.in      tool-versions.txt
.PP
First, search for a string (independent of case) throughout the current directory and all subdirectories:
.PP
~/src/findutils-4.7.0# \fBsrch find.c\fP
.br
\&./find/oldfind.c
.br
\&./find/ftsfind.c
.PP
This is the fastest form, where any file/dir matching the shell expression *find.c* is printed.
.PP
Next, search for a file name matching the exact string we type:
.PP
~/src/findutils-4.7.0# \fBsrch -n ^find\\$\fP
.br
\&./find
.br
\&./tests/find
.br
\&./find/find
.br
~/src/findutils-4.7.0# \fBfind -name find\fP
.br
\&./find
.br
\&./find/find
.br
\&./tests/find
.PP
Because of the parallel nature of \fBsrch\fP, the output order is random. You might pipe the output through \fBsort\fP(1) to make it "nicer".
.PP
Last, a bit more complex example, where we list plain files not ending in ".c" nor ".h", and excluding directory "testsuite":
.PP
~/src/findutils-4.7.0# srch -fn '!.c$|.h$' -E testsuite find
.br
find
.br
find/Makefile.am
.br
find/Makefile.in
.br
find/find.1
.RE
.PP

.IP \(bu 3
\fBExample 2\fP:
Count files matching shell pattern '*e*' starting from current directory, and compare run-time with \fBfind\fP(1) on an otherwise idle 40-CPU Cisco UCSC-C220-M4S running RHEL 9.0 with an ext4 FS on a 110.8G SSD drive. \fBSrch\fP will by default use 8 of the cores.
.RS
.PP
First, we give \fBfind\fP(1) a try.
.PP
~$ \fBclearcache ; \\time -p find -iname '*e*' | wc -l\fP
.br
real 337.78
.br
user 72.37
.br
sys 57.96
.br
62053918
.PP
Then we try \fBsrch\fP(1) with the default number of CPU cores.
.PP
~$ \fBclearcache ; \\time -p srch -w e\fP
.br
62053918
.br
real 38.49
.br
user 11.74
.br
sys 62.28
.PP
We can also test with twice as many CPU cores.
.PP
~$ \fBclearcache ; \\time -p srch -wt16 e\fP
.br
62053918
.br
real 22.15
.br
user 12.84
.br
sys 67.94
.PP
Instead of calling \fBtime\fP(1), we can use the built-in timing functionality:
.PP
~$ \fBclearcache ; srch -wTt32 e\fP
.br
62053918
.br
Real: 14.77 seconds
.PP
Option \fB-T\fP is a simplified version of \fBtime\fP(1).  This is particularly useful on Windows unless you use PowerShell and Measure-Command.
.PP
"Measure-Command {$count=srch -wt32 e}; Write-Host $count}|Select-Object Seconds" should give the same on Windows.
.PP
The \fBclearcache\fP command used above is a small script containing 2 commands:
.PP
sync; echo 3 > /proc/sys/vm/drop_caches
.RE
.RE
.PP

.IP \(bu 3
\fBExample 3\fP:
Count all files excluding directory .snapshot, on an NFS share from an old NetApp, and compare run-time with \fBfind\fP(1) on the same 40-CPU Cisco UCSC-C220-M4S running RHEL 9.0 as in the previous example. \fBSrch\fP will use 8 of the cores unless option -t is given.
.RS
.PP
~$ \fBclearcache ; \\time -p srch -wZ\fP
.br
2230031
.br
real 49.05
.br
user 3.16
.br
sys 42.02
.PP
~$ \fBclearcache ; \\time -p find -name .snapshot -prune -o -print | wc -l\fP
.br
real 251.03
.br
user 9.63
.br
sys 48.38
.br
2230031
.PP
The -Z option (equal to -E.snapshot) is always recommended when searching on NAS via NFS.
.RE
.RE
.PP

.IP \(bu 3
\fBExample 4\fP:
Find the 3 biggest files in a directory tree.  For a real heavy duty test, we have a file system containing nearly 369 million files. This is a striped ext4 file system, consisting of two 110GiB SSD disks, on the same 40-CPU Cisco UCSC-C220-M4S running RHEL 9.0 as in the previous examples, filled with empty versions of real production files.  3 big files (ff1, ff2, ff3) have been manually created using \fBfallocate\fP(1).  File systems containing this many files probably aren't mainstream (yet), but serves the purpose of showing the capabilities of \fBsrch\fP compared to standard Linux/Unix utilities.
.RS
.PP
Instantly locating the fattest files can be particularly useful if we notice that a file system is filling up, and we quickly want to see if there is a single file growing endlessly.
.PP
First, count the files, and compare run-time with \fBfind\fP + \fBwc\fP, to see the speed difference when utilizing 24 threads (\fBsrch\fP) compared to 1 thread (\fBfind\fP).
.PP
~# \fBdf -h /mnt/stripe\fP
.br
Filesystem                  Size  Used Avail Use% Mounted on
.br
/dev/mapper/striped-stripe  102G   24G   68G  26% /mnt/stripe
.br
~# 
.br
~# \fBclearcache ; \\time -p srch -wt24 /mnt/stripe/bigtree\fP
.br
368928452
.br
real 57.09
.br
user 32.84
.br
sys 227.84
.br
~# 
.br
~# \fBclearcache ; \\time -p find /mnt/stripe/bigtree | wc -l\fP
.br
real 1005.88
.br
user 144.81
.br
sys 189.22
.br
368928452
.PP
Observe that just the \fBfind\fP part is timed here.  The \fBwc\fP part of the pipeline is not covered by \fBtime\fP, so the comparison with \fBsrch\fP can be said to be "fair" since there is no overhead from external utilities.
.PP
It is also interesting to compare with another fast, file finder, namely \fBfd-find\fP.
.PP
~# \fBclearcache ; \\time -p fd -uu -j24 . /mnt/stripe/bigtree | wc -l\fP
.br
real 457.15
.br
user 2639.26
.br
sys 7461.55
.br
368928451
.PP
Now, locate the three biggest files, using the -F3 option.  Note that this operation is much slower than counting the files, because the program has to \fBlstat\fP(2) each and every file to get the size.   Use option -f to just consider ordinary files.
.PP
~# \fBclearcache ; \\time -p srch -fF3 /mnt/stripe/bigtree\fP
.br
104857600           /mnt/stripe/bigtree/archive/log/2018/64/11/59/ff1
.br
209715200           /mnt/stripe/bigtree/archive/log/2018/64/11/52/ff2
.br
314572800           /mnt/stripe/bigtree/archive/log/2018/69/10/42/ff3
.br
real 1300.70
.br
user 326.63
.br
sys 8781.89
.PP
Using GNU \fBfind\fP + \fBsort\fP + \fBtail\fP:
.PP
~# \fBclearcache ; find /mnt/stripe/bigtree -type f -printf "%s\\t%p\\n" | env LC_ALL=C sort -nT/tmpsort | \\time -p tail -3\fP
.br
104857600       /mnt/stripe/bigtree/archive/log/2018/64/11/59/ff1
.br
209715200       /mnt/stripe/bigtree/archive/log/2018/64/11/52/ff2
.br
314572800       /mnt/stripe/bigtree/archive/log/2018/69/10/42/ff3
.br
real 4699.45
.br
user 13.74
.br
sys 12.86
.PP
Without the LC_ALL=C setting before calling \fBsort\fP, sorting may take a very long time.  Note that \fBtime\fP is placed before \fBtail\fP because the \fBfind\fP command will finish long before \fBtail\fP.
.RE
.RE
.PP

.IP \(bu 3
\fBExample 5\fP: Find the 3 most recently modified files.
.RS
.PP
To determine hot spots in the file system, we can use option -fMx to list out the x most recently updated files.
.PP
~# \fBclearcache ; \\time -p srch -fM3 /mnt/stripe/bigtree\fP
.br
2022-08-04 08:10:44 /mnt/stripe/bigtree/archive/log/2018/64/11/59/ff1
.br
2022-08-04 08:10:50 /mnt/stripe/bigtree/archive/log/2018/64/11/52/ff2
.br
2022-08-04 08:10:57 /mnt/stripe/bigtree/archive/log/2018/69/10/42/ff3
.br
real 1286.15
.br
user 299.17
.br
sys 8723.87
.br
~# 
.br
~# \fBclearcache ; find /mnt/stripe/bigtree -type f -printf "%T+ %p\\n" | sed 's/+/ /;s/\\.[0-9]*//' | \\
.br
env LC_ALL=C sort -T/tmpsort | \\time -p tail -3\fP
.br
2022-08-04 08:10:44 /mnt/stripe/bigtree/archive/log/2018/64/11/59/ff1
.br
2022-08-04 08:10:50 /mnt/stripe/bigtree/archive/log/2018/64/11/52/ff2
.br
2022-08-04 08:10:57 /mnt/stripe/bigtree/archive/log/2018/69/10/42/ff3
.br
real 5970.59
.br
user 11.58
.br
sys 14.24
.PP
/tmpsort is a dedicated file system for the temporary files generated by sort.  It is created like this:
.PP
~# \fBmount -t tmpfs -o rw,nodev,nosuid,noexec,noatime,size=50G tmpfssort /tmpsort\fP
.RE
.RE
.PP

.IP \(bu 3
\fBExample 6\fP: Find the 3 directories containing the highest number of files.
.RS
.PP
This can be particularly interesting when looking for the reason that a file system is filling up or running out of inodes.  No \fBlstat\fP(2) is needed on the files this time, so this is a much faster operation than the previous two examples.
.PP
~# \fBclearcache ; \\time -p srch -t16 -D3 /mnt/stripe/bigtree\fP
.br
882315              /mnt/stripe/bigtree/archive/ArchiveFile/2021-11/26/15
.br
971202              /mnt/stripe/bigtree/archive/ArchiveFile/2021-12/13/15
.br
1166852             /mnt/stripe/bigtree/archive/ArchiveFile/2021-11/30/15
.br
real 73.15
.br
user 31.76
.br
sys 220.40
.br
~# 
.br
~# \fBclearcache ; find /mnt/stripe/bigtree -type d -print0 | \\\fP
.br
\fBxargs -0n1 sh -c 'echo "$(find "$0" -maxdepth 1 | tail -n +2 | wc -l) $0"' | \\\fP
.br
\fBenv LC_ALL=C sort -nT/tmpsort | \\time -p tail -3\fP
.br
882315 /mnt/stripe/bigtree/archive/ArchiveFile/2021-11/26/15
.br
971202 /mnt/stripe/bigtree/archive/ArchiveFile/2021-12/13/15
.br
1166852 /mnt/stripe/bigtree/archive/ArchiveFile/2021-11/30/15
.br
real 1899.39
.br
user 0.01
.br
sys 0.03
.PP
Maybe it would be faster using \fBls\fP than \fBfind\fP for listing all the files in a directory:
.PP
~# \fBclearcache ; find /mnt/stripe/bigtree -type d -print0 | \\\fP
.br
\fBxargs -0n1 sh -c 'echo "$(ls -AU "$0" | wc -l) $0"' | \\\fP
.br
\fBenv LC_ALL=C sort -nT/tmpsort | \\time -p tail -3\fP
.br
882315 /mnt/stripe/bigtree/archive/ArchiveFile/2021-11/26/15
.br
971202 /mnt/stripe/bigtree/archive/ArchiveFile/2021-12/13/15
.br
1166852 /mnt/stripe/bigtree/archive/ArchiveFile/2021-11/30/15
.br
real 1834.21
.br
user 0.01
.br
sys 0.00
.PP
Nope, almost exactly the same.
.RE
.RE
.PP

.IP \(bu 3
\fBExample 7\fP: Finding disk usage like \fBdu\fP(1).

~# \fBclearcache ; \\time -p srch -H /mnt/stripe/bigtree\fP
.br
23.1G   /mnt/stripe/bigtree
.br
real 1291.19
.br
user 235.14
.br
sys 8815.39
.br
~#
.br
~# \fBclearcache ; \\time -p du -hs /mnt/stripe/bigtree\fP
.br
24G     /mnt/stripe/bigtree
.br
real 3307.76
.br
user 316.93
.br
sys 2089.41
.RE
.RE
.PP

.IP \(bu 3
\fBExample 8\fP: Playing with an idle IBM ESS array with real spindles.

~# \fBdf -h /gpfs/gpfs0\fP
.br
Filesystem      Size  Used Avail Use% Mounted on
.br
/dev/gpfs0      1,5P  8,1G  1,5P   1% /gpfs/gpfs0

Here we have about 130 million zero-sized test files.

~# \fBclearchache ; \\time -p srch -w /gpfs/gpfs0/bigtree\fP
.br
130450061
.br
real 1260.56
.br
user 59.65
.br
sys 265.01

We can probably count faster if we throw in some more threads.

~# \fBgrep proc /proc/cpuinfo | wc -l\fP
.br
160

Adding 2 and 2 threads until the point where there is no longer any desired effect of extra threads.

~# \fBclearcache ; \\time -p srch -wt94 /gpfs/gpfs0/bigtree\fP
.br
130450061
.br
real 209.65
.br
user 112.67
.br
sys 481.79

The best result is achieved with 94 threads on the EMS node in this cluster, and 209.65 seconds is the average over 10 tests.  The expectation is that adding threads will only be beneficial up to a certain point, after which the overhead of more threads will be higher than the gain. This effect is clearly seen here.  Using more than 94 threads just gives increased run-times.  Using 160 threads gives real = 214.95.

Let's see what a single-threaded \fBfind\fP can give.  Again we run 10 tests, and calculate the average.

~# \fBclearcache ; \\time -p find /gpfs/gpfs0/bigtree | wc -l\fP
.br
real 7715.57
.br
user 108.27
.br
sys 228.11
.br
130450061

3.5 minutes for \fBsrch\fP compared to 128.6 minutes for \fBfind\fP(1) is almost 37 times faster, but CPU cost for \fBsrch\fP is of course a lot higher than for \fBfind\fP(1).
.RE
.RE
.PP

.IP \(bu 3
\fBExample 9\fP: Testing the -Q option on a spinning disk.

When we perform a \fBsrch\fP on a single or mirrored spinning disk, using the inode based queueing algorithm might speed things up considerably.
Here we use an old 3GHz 16-core SPARC T4-4 equipped with 4 x 600 GB internal disks.

~# \fBuname -a\fP
.br
SunOS sunbeam 5.11 11.3 sun4v sparc sun4v
.br
~# 
.br
~# \fBzfs list -r ipspool\fP
.br
NAME            USED  AVAIL  REFER  MOUNTPOINT
.br
ipspool        84.7G   463G    31K  /ipspool
.br
ipspool/depot  56.6G   463G  56.6G  /depot
.br
ipspool/repo   28.1G   463G  28.1G  /repo
.br
~# 
.br
~# \fBzpool status ipspool\fP
.br
  pool: ipspool
.br
 state: ONLINE
.br
  scan: resilvered 36.0G in 8m01s with 0 errors on Thu Nov 16 10:25:20 2017
.br

.br
config:
.br

.br
        NAME                       STATE     READ WRITE CKSUM
.br
        ipspool                    ONLINE       0     0     0
.br
          mirror-0                 ONLINE       0     0     0
.br
            c0t5000CCA025ABAE24d0  ONLINE       0     0     0
.br
            c0t5000CCA025B6FCB0d0  ONLINE       0     0     0
.br

errors: No known data errors
.br
~# 
.br
~# \fBecho | format\fP
.br
Searching for disks...done
.br
.br
AVAILABLE DISK SELECTIONS:
.br
       0. c0t5000CCA025AC3A84d0 <HITACHI-H106060SDSUN600G-A2B0-558.91GB>
.br
          /scsi_vhci/disk@g5000cca025ac3a84
.br
          /dev/chassis/SYS/MB/HDD0/disk
.br
       1. c0t5000CCA025C551F4d0 <HITACHI-H106060SDSUN600G-A2B0-558.91GB>
.br
          /scsi_vhci/disk@g5000cca025c551f4
.br
          /dev/chassis/SYS/MB/HDD1/disk
.br
       2. c0t5000CCA025ABAE24d0 <HITACHI-H106060SDSUN600G-A2B0-558.91GB>
.br
          /scsi_vhci/disk@g5000cca025abae24
.br
          /dev/chassis/SYS/MB/HDD2/disk
.br
       3. c0t5000CCA025B6FCB0d0 <HITACHI-H106060SDSUN600G-A2B0-558.91GB>
          /scsi_vhci/disk@g5000cca025b6fcb0
.br
          /dev/chassis/SYS/MB/HDD3/disk
.br
Specify disk (enter its number): Specify disk (enter its number): 
.br
~# 
.br
~# \fBzpool export ipspool ; zpool import ipspool ; \\time find /repo | wc -l\fP

real     1:46.2
.br
user        2.1
.br
sys        27.3
.br
  600326
.br
~# 
.br
~# \fBzpool export ipspool ; zpool import ipspool; \\time srch -w /repo\fP
.br
600326
.br
real       32.7
.br
user        0.4
.br
sys         2.3

Now, let's try the magical -Q option.

~# \fBzpool export ipspool ; zpool import ipspool ; \\time srch -wQ /repo\fP
.br
600326
.br
real       16.2
.br
user        0.5
.br
sys         2.5

We can see a similar effect on a completely different architechture, an old HP-UX server.

root@knoll /home/root# \fBuname -a\fP
.br
HP-UX knoll B.11.31 U ia64 1234567890 unlimited-user license
.br
root@knoll /home/root#
.br
root@knoll /home/root# \fBmachinfo | head -4\fP
.br
CPU info:
.br
  2 Intel(R) Itanium 2 processors (1.6 GHz, 6 MB)
.br
          400 MT/s bus, CPU version A1

root@knoll /home/root# \fBumount /vxfs && mount /vxfs && \\time find /vxfs | wc -l\fP

real    15:47.1
.br
user       24.6
.br
sys      4:30.5
.br
12254679
.br
root@knoll /home/root# \fBumount /vxfs && mount /vxfs && \\time srch -w /vxfs\fP
.br
12254679

real     7:58.2
.br
user       22.3
.br
sys      1:22.0
.br
root@knoll /home/root# \fBumount /vxfs && mount /vxfs && \\time srch -wQ /vxfs\fP
.br
12254679
.br

real     5:53.5
.br
user       25.6
.br
sys      1:24.1

Also on AIX we can see the effect of the -Q option.

root@power8 /# \fBuname -a\fP
.br
AIX power8 2 7 001122334400
.br
root@power8 /# \fBoslevel\fP
.br
7.2.0.0
.br
root@power8 /# \fBwhich find\fP
.br
/usr/bin/find
.br
root@power8 /# \fBwhat /usr/bin/find\fP
.br
/usr/bin/find:
.br
        61      1.16  src/bos/usr/ccs/lib/libc/__threads_init.c, libcthrd, bos720 8/2/07 13:09:21
.br
        40        1.83.23.5  src/bos/usr/bin/find/find.c, cmdscan, bos72V, v2020_28A1 6/29/20 13:14:38
.br
root@power8 /# \fB\\echo "Arch: \\c" && lsattr -El proc0 | awk '/type/ {print $2}'\fP
.br
Arch: PowerPC_POWER8
.br
root@power8 /# \fB\\echo "CPU: \\c" && lsdev -Ccprocessor | awk '{n+=1} END {printf "%d x ", n}' && lsattr -El proc0 | awk '/freq/ {print int($2/1000/1000) "MHz"}'\fP
.br
CPU: 12 x 3891MHz
.br
root@power8 /# \fBuptime\fP
.br
  09:09AM   up 33 days,  18:13,  1 user,  load average: 0.29, 0.40, 0.41
.br
root@power8 /# 
.br
root@power8 /# \fBumount /testfs ; mount /testfs ; \\time find /testfs | wc -l\fP

real   77.56
.br
user   1.60
.br
sys    14.15
.br
 2014158
.br
root@power8 /# \fBumount /testfs ; mount /testfs ; \\time srch -w /testfs\fP
.br
2014158
.br

real   53.24
.br
user   2.36
.br
sys    11.08
.br
root@power8 /# \fBumount /testfs ; mount /testfs ; \\time srch -wQ /testfs\fP
.br
2014158

real   44.67
.br
user   2.91
.br
sys    10.73

Finally we run some tests on an old, decommissioned IBM V7000 with only internal disk left.

~# \fBdmidecode | grep 'IBM Sys'\fP
.br
        Product Name: IBM System x3650 M4: -[xxxxxxx]-
.br
~# \fBuname -a\fP
.br
Linux mgmt001st001 2.6.32-358.41.1.el6.x86_64 #1 SMP Mon Apr 21 15:58:42 EDT 2014 x86_64 x86_64 x86_64 GNU/Linux
.br
~# \fBgrep proc /proc/cpuinfo | wc -l\fP
.br
4
.br
~# \fBfind --version | head -1\fP
.br
find (GNU findutils) 4.4.2
.br
~# \fBumount /mnt/ext4 ; mount /mnt/ext4 ; \\time -p find /mnt/ext4 | wc -l\fP
.br
real 184.82
.br
user 0.91
.br
sys 3.39
.br
341988
.br
~# \fBumount /mnt/ext4 ; mount /mnt/ext4 ; \\time -p srch -w /mnt/ext4\fP
.br
341988
.br
real 93.52
.br
user 0.62
.br
sys 3.45
.br
~# \fBumount /mnt/ext4 ; mount /mnt/ext4 ; \\time -p srch -wQ /mnt/ext4\fP
.br
341988
.br
real 15.70
.br
user 0.56
.br
sys 2.96

No doubt that the queue sorted on inode numbers gave best performance, at least in these cases, but there is of course no guarantee that this is always the case.  Particularly, if the directory structure is cached in memory, the difference in run-times will be low.

.RS
.SH CREDITS
.IP \(bu 3
The program contains code inspired by https://github.com/xaionaro/libpftw.
.IP \(bu 3
The program makes use of heap algorithms derived from https://gist.github.com/martinkunev/1365481.
.IP \(bu 3
The program makes direct use of heap struct and a couple of routines from BusyBox' `du' code, https://busybox.net.
.IP \(bu 3
The program makes use of a slightly modified version of https://github.com/coapp-packages/libgnurx when being built for Windows (using MinGW on Linux).

.SH NOTES
.IP \(bu 3
Note that symlinks below the start point(s), pointing to directories, are never followed.
.IP \(bu 3
Warning: This program may impose a very high load on your storage systems when utilizing many CPU cores.
.IP \(bu 3
The "\fBsrch\fP" program comes with ABSOLUTELY NO WARRANTY.
This is free software, and you are welcome
to redistribute it under certain conditions.
See the GNU General Public Licence for details.

.SH SEE ALSO
\fBfind\fP(1), \fBlocate\fP(1), \fBfd-find/fd\fP(1), \fBsort\fP(1), \fBtime\fP(1), \fBxargs\fP(1), \fBwc\fP(1), \fBtail\fP(1), \fBdu(1)\fP

.SH AUTHOR
\fBSrch\fP was written by J\[/o]rn I. Viken, jornv@1337.no.
